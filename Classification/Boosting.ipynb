{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree based model's Algorithm (Boosting) \n",
    "\n",
    "여러개의 week learner들을 조합하여 분류 성능을 높인다.\n",
    "\n",
    "Bagging 과의 차이점은 Parallel 하지 않고 Sequencial 하다는 것이다.\n",
    "\n",
    "<img src = \"https://drive.google.com/uc?id=1SBo3Rf6i1rDOMJv7_1ZPy6EmOK24raQM\" width = 500 height = 300>\n",
    "\n",
    "Boosting 은 여러 개의 모델을 만들고 한 모델에서 발생한 오차에 가중치를 두고\n",
    "\n",
    "다음 모델에서 가중치를 두어 오차 부분을 잘 학습할 수 있게 해주는 알고리즘이다.\n",
    "\n",
    "<img src = \"https://drive.google.com/uc?id=1nghSWi5Ye9StBZ3h2H9DvxwW9pfPCcez\" width = 500 height = 300>\n",
    "\n",
    "위의 사진과 같이 제대로 학습하지 못한 부분들에 가중치를 두어 다음 학습 때 학습할 수 있도록 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting (hot)\n",
    "\n",
    "Gradient Boosting 은 학습하지 못한 부분에 가중치를 두는 방식이 아닌 잔차들을 학습하는 방식입니다\n",
    "\n",
    "이전 모델이 예측에 실패한 만큼을 다시 학습하며 오차를 줄여나가는 방식입니다.\n",
    "\n",
    "<img src=\"https://i.imgur.com/iOFnWMl.png\" width=700/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 대표적 -> LGBM , XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost 파라미터\n",
    "\n",
    "nthread = CPU 실행 스레드 정하기 Default가 전부사용\n",
    "\n",
    "min_child_weight = 관측치 가중합의 최소 값이 크면 과적합 감소 ★\n",
    "\n",
    "max_depth = 트리 깊이 조절 ★\n",
    "\n",
    "subsample = 데이터 샘플링 비율 (보통 .5 ~ 1)\n",
    "\n",
    "colsample_bytree = 각 트리마다 피쳐를 얼마나 샘플링할 것인지 (보통 .5 ~ 1) ★\n",
    "\n",
    "reg_lambda = l2 penalty\n",
    "\n",
    "reg_alpha = l1 penalty\n",
    "\n",
    "scale_pos_weight = 불균형한 데이터셋에서 부족한 쪽에 가중치 (neg / pos) ★\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM 파라미터 (학습 시간이 짧음, 용량 큰 데이터도 괜찮음.)\n",
    "\n",
    "num_iterations\t= XGB에서의 n_estimators\n",
    "\n",
    "objective = binary , regression\n",
    "\n",
    "learning_rate = learning_rate\n",
    "\n",
    "min_data_in_leaf = XGB에서의 min_child_weight ★\n",
    "\n",
    "max_depth = 트리 깊이 조절 ★\n",
    "\n",
    "num_leaves = 개별트리가 가질 수 있는 최대 리프 수 ★\n",
    "\n",
    "boosting = 부스팅 방법, gbdt or rf\n",
    "\n",
    "bagging_fraction = XGB에서의 subsample\n",
    "\n",
    "feature_fraction = 개별트리가 학습 할 때 무작위로 선택하는 feature의 비율\n",
    "\n",
    "metric = 성능평가를 무엇으로 할 것인지 auc, l1, l2, roc ★"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
