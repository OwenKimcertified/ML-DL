{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 데이터가 선형적이지 않다면 우리는 그 데이터를 분류를 이용하여 패턴을 예측할 수 있습니다.\n",
    "\n",
    "트리기반모델은 회귀와 분류 문제에서 모두 쓰일 수 있는 장점이 있습니다.\n",
    "\n",
    "하지만 오늘은 분류 문제에 대해 정리해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline,Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.model_selection import train_test_split\n",
    "from category_encoders import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "<img src = \"https://drive.google.com/uc?id=1_INZ08l3RVtfDWO9sI3ZdmMTrQ9JpbpO\" width = 500 height = 300>\n",
    "\n",
    "\n",
    "결정트리는 비용함수(Impurity)를 최소화 하는 특성의 값을 Yes / No 라는 binary한 기준으로 분류해나가는 과정입니다.\n",
    "\n",
    "이를 데이터를 기반으로 모델을 만든다고 했을 때는\n",
    "\n",
    "<img src = \"https://drive.google.com/uc?id=1reG0sT9WzLXWyj187hwMS95w52MRXX3j\" width = 500 height = 300>\n",
    "\n",
    "이런식으로 만들어질 수 있겠습니다.\n",
    "\n",
    "각 노드들은 특성이 나뉘는 기준이 무엇이고, 그 기준에 의해 나눠진 특성들이 존재함을 알 수 있습니다.\n",
    "\n",
    "각 노드들의 위치는 gini impurity 라는 비용함수를 기준으로 정해집니다.\n",
    "\n",
    "위의 과정에서 자연스럽게 우리는 비선형적인 데이터에서 각 피쳐간의 연관성을 포착할 수 있게된다는 장점이 있습니다.\n",
    "\n",
    "예를 들어 왼쪽의 경우를 보면 키가 180이 넘는 사람들을 보았을 때 남자가 719명, 여자가 281명인 것을 보아 \n",
    "\n",
    "키가 180이 넘으면 보통 남자다 라는 특성이 포착되는 것을 알 수 있다는 말입니다.\n",
    "\n",
    "만약 데이터를 관성적으로 스케일링한다 했을 때 그 트리를 시각화 한다면, 180이라는 기준값이 스케일링 돼버리니\n",
    "\n",
    "시각화라는 장점이 사라지게 돼버립니다. 또한 결측치의 부분도 결측치 자체가 하나의 지표가 될 수 있기 때문에\n",
    "\n",
    "분류문제에서는 간단하게 생각할 부분이 아닙니다.(무턱대고 fill하면 안된다는 말 입니다.)\n",
    "\n",
    "그래서 요약하자면, 트리기반모델에서는 많은 전처리가 필요없다는 편리함과 시각화에 장점이 있다고 말할 수 있겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "타겟을 보고 binary한지 아닌지를 파악하고  분류를 이용할지말지 결정합니다. \n",
    "\n",
    "만약 비율 자체가 불균형하다면 stratify로 각 데이터들을 분할할 때 같은 비율로 분할한 후 \n",
    "\n",
    "모델을 학습할 때 상대적으로 적은 비중에 가중치를 두어(Treshold를 올리고 내리고) 모델이 데이터를 학습하기 원활하게 도와줘야 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 특성이 얼마나 먼저, 많이 분기에 사용되었는지로 정의된 특성 중요도를 보고 각 특성이 얼마나 크리티컬 했는지를 아는 방법도 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomforest \n",
    "\n",
    "랜덤포레스트는 각각의 DT들이 모여서 숲을 이루었다고 생각하면 쉽습니다.\n",
    "\n",
    "각 트리에서 랜덤하게 도출된 결과값들을 취합하여 최종적인 결과를 도출합니다.\n",
    "\n",
    "이를 Bootstrap Aggregating Bagging 이라 합니다.\n",
    "\n",
    "따라서 RF로 만든 모델은 분산을 줄이고 편향을 늘려 과적합을 피할 수 있고, 일반화 성능을 더 좋게 만들어 줄 수 있습니다.\n",
    "\n",
    "또한 Bootstrap 과정에서 사용되지 않은 데이터들(복원 추출이기 때문)은 따로 모아 검증에 활용할 수도 있습니다. (out of bagging oob라 칭합니다.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
